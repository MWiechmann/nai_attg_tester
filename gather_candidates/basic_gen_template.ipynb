{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import asyncio\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import configparser\n",
    "import ast\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from novelai_api.NovelAI_API import NovelAIAPI\n",
    "from novelai_api.Preset import Model, Preset\n",
    "from novelai_api.GlobalSettings import GlobalSettings\n",
    "from novelai_api.Tokenizer import Tokenizer\n",
    "from novelai_api.utils import b64_to_tokens\n",
    "from novelai_api.BiasGroup import BiasGroup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings new method\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('genre_clio_settings.ini')\n",
    "\n",
    "# Access the General Settings\n",
    "run_name = config['GENERAL']['run_name']\n",
    "auth_method = config['GENERAL']['auth_method']\n",
    "\n",
    "# Access the Generation Settings\n",
    "delay_time = int(config['GENERATION SETTINGS']['delay_time'])\n",
    "generation_timeout = int(config['GENERATION SETTINGS']['generation_timeout'])\n",
    "max_failed_gens = int(config['GENERATION SETTINGS']['max_failed_gens'])\n",
    "candidates_goal = int(config['GENERATION SETTINGS']['candidates_goal'])\n",
    "bias_strength_inc = float(config['GENERATION SETTINGS']['bias_strength_inc'])\n",
    "bias_phrases = ast.literal_eval(config['GENERATION SETTINGS']['bias_phrases'])\n",
    "model_class, model_attr = config['GENERATION SETTINGS']['model'].split('.')\n",
    "model = getattr(globals()[model_class], model_attr)\n",
    "prompt = config['GENERATION SETTINGS']['prompt']\n",
    "stop_sequences = ast.literal_eval(config['GENERATION SETTINGS']['stop_sequences'])\n",
    "\n",
    "# Access the Preset Configuration\n",
    "preset_method = config['PRESET']['preset_method']\n",
    "preset_name = config['PRESET']['preset_name']\n",
    "preset_stop_sequences = ast.literal_eval(config['PRESET']['preset_stop_sequences'])\n",
    "preset_temperature = float(config['PRESET']['preset_temperature'])\n",
    "preset_max_length = int(config['PRESET']['preset_max_length'])\n",
    "preset_min_length = int(config['PRESET']['preset_min_length'])\n",
    "preset_top_k = int(config['PRESET']['preset_top_k'])\n",
    "preset_top_a = float(config['PRESET']['preset_top_a'])\n",
    "preset_top_p = float(config['PRESET']['preset_top_p'])\n",
    "preset_typical_p = float(config['PRESET']['preset_typical_p'])\n",
    "preset_tail_free_sampling = float(config['PRESET']['preset_tail_free_sampling'])\n",
    "preset_repetition_penalty = float(config['PRESET']['preset_repetition_penalty'])\n",
    "preset_repetition_penalty_range = int(config['PRESET']['preset_repetition_penalty_range'])\n",
    "preset_repetition_penalty_slope = float(config['PRESET']['preset_repetition_penalty_slope'])\n",
    "preset_repetition_penalty_frequency = float(config['PRESET']['preset_repetition_penalty_frequency'])\n",
    "preset_repetition_penalty_presence = float(config['PRESET']['preset_repetition_penalty_presence'])\n",
    "preset_repetition_penalty_whitelist = ast.literal_eval(config['PRESET']['preset_repetition_penalty_whitelist'])\n",
    "preset_repetition_penalty_default_whitelist = config['PRESET']['preset_repetition_penalty_default_whitelist'] == 'True'\n",
    "preset_length_penalty = float(config['PRESET']['preset_length_penalty'])\n",
    "preset_diversity_penalty = float(config['PRESET']['preset_diversity_penalty'])\n",
    "preset_order = ast.literal_eval(config['PRESET']['preset_order'])\n",
    "preset_phrase_rep_pen = config['PRESET']['preset_phrase_rep_pen']\n",
    "\n",
    "# Assuming Preset is a class you have defined or imported\n",
    "preset = Preset(name=preset_name, model=model, settings={\n",
    "    'temperature': preset_temperature,\n",
    "    'max_length': preset_max_length,\n",
    "    'min_length': preset_min_length,\n",
    "    'top_k': preset_top_k,\n",
    "    'top_a': preset_top_a,\n",
    "    'top_p': preset_top_p,\n",
    "    'typical_p': preset_typical_p,\n",
    "    'tail_free_sampling': preset_tail_free_sampling,\n",
    "    'repetition_penalty': preset_repetition_penalty,\n",
    "    'repetition_penalty_range': preset_repetition_penalty_range,\n",
    "    'repetition_penalty_slope': preset_repetition_penalty_slope,\n",
    "    'repetition_penalty_frequency': preset_repetition_penalty_frequency,\n",
    "    'repetition_penalty_presence': preset_repetition_penalty_presence,\n",
    "    'repetition_penalty_whitelist': preset_repetition_penalty_whitelist,\n",
    "    'repetition_penalty_default_whitelist': preset_repetition_penalty_default_whitelist,\n",
    "    'length_penalty': preset_length_penalty,\n",
    "    'diversity_penalty': preset_diversity_penalty,\n",
    "    'order': preset_order,\n",
    "    'phrase_rep_pen': preset_phrase_rep_pen,\n",
    "})\n",
    "\n",
    "auth = False\n",
    "env = os.environ\n",
    "\n",
    "# Init variable for login method\n",
    "if auth_method == \"enter_key\":\n",
    "    auth = input(\"Enter your NovelAI access key: \")\n",
    "if auth_method == \"enter_token\":\n",
    "    auth = input(\"Enter your NovelAI access token: \")\n",
    "elif auth_method == \"enter_login\":\n",
    "    auth = {}\n",
    "    auth[\"user\"] = input(\"Enter your NovelAI username: \")\n",
    "    auth[\"pw\"] = input(\"Enter your NovelAI password: \")\n",
    "elif auth_method == \"env_key\":\n",
    "    auth = env[\"NAI_KEY\"]\n",
    "elif auth_method == \"env_token\":\n",
    "    auth = env[\"NAI_TOKEN\"]\n",
    "elif auth_method == \"env_login\":\n",
    "    auth = {}\n",
    "    auth[\"user\"] = env[\"NAI_USERNAME\"]\n",
    "    auth[\"pw\"] = env[\"NAI_PASSWORD\"]\n",
    "else:\n",
    "    raise RuntimeError(\n",
    "        \"Invalid value for 'auth_method'. Must be one of 'enter_key', 'enter_token', 'enter_login', env_key', 'env_token' or 'env_login\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def nai_login(api, auth_method, auth):\n",
    "    if auth_method == \"enter_key\" or auth_method == \"env_key\":\n",
    "        await api.high_level.login_from_key(auth)\n",
    "    elif auth_method == \"enter_token\" or auth_method == \"env_token\":\n",
    "        await api.high_level.login_with_token(auth)\n",
    "    elif auth_method == \"enter_login\" or auth_method == \"env_login\":\n",
    "        await api.high_level.login(auth[\"user\"], auth[\"pw\"])\n",
    "\n",
    "async def gen_attg_candidate(\n",
    "    model=Model.Clio,\n",
    "    preset = \"Edgewise\",\n",
    "    prompt=\"[ Genre:\",\n",
    "    stop_sequences=[\",\", \";\", \" ]\",\"\\n\"],\n",
    "    cut_stop_seq=True,\n",
    "    auth_method=\"env_token\",\n",
    "    auth=None,\n",
    "    bias_groups=None,\n",
    "):\n",
    "    # Initialize the NovelAI API\n",
    "    api = NovelAIAPI()\n",
    "\n",
    "    try:\n",
    "        # Ensure you're logged in\n",
    "        await nai_login(api, auth_method, auth)\n",
    "\n",
    "        # If preset is a string, get the official preset with that name for the specified model\n",
    "        if isinstance(preset, str):\n",
    "            preset = Preset.from_official(model, preset)\n",
    "\n",
    "        # Tokenize the stop sequences and set them for the preset\n",
    "        stop_sequences_tokenized = [\n",
    "            Tokenizer.encode(model, seq) for seq in stop_sequences\n",
    "        ]\n",
    "        preset[\"stop_sequences\"] = stop_sequences_tokenized\n",
    "\n",
    "        # Create default global settings\n",
    "        global_settings = GlobalSettings()\n",
    "\n",
    "        gen = await api.high_level.generate(\n",
    "            prompt, model, preset, global_settings, None, bias_groups, None\n",
    "        )\n",
    "\n",
    "        # After generating the text, remove the stop sequence\n",
    "        generated_text = Tokenizer.decode(model, b64_to_tokens(gen[\"output\"]))\n",
    "        if cut_stop_seq:\n",
    "            for seq in stop_sequences:\n",
    "                generated_text = re.sub(\n",
    "                    re.escape(seq) + \"$\", \"\", generated_text\n",
    "                ).strip()\n",
    "\n",
    "        return generated_text\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error generating text: {e}\")\n",
    "\n",
    "def update_bias_groups(phrase, bias_phrase_dict, bias_strength_inc, bias_groups):\n",
    "    # Update the bias strength for the phrase or add it if it's not in the dict\n",
    "    if phrase in bias_phrase_dict:\n",
    "        bias_phrase_dict[phrase] += bias_strength_inc\n",
    "    else:\n",
    "        bias_phrase_dict[phrase] = bias_strength_inc\n",
    "\n",
    "    # Clear the existing bias groups\n",
    "    bias_groups.clear()\n",
    "\n",
    "    # Regenerate the bias groups based on the updated bias_phrase_dict\n",
    "    for phrase, strength in bias_phrase_dict.items():\n",
    "        bg = BiasGroup(strength)\n",
    "        bg.add(phrase)\n",
    "        bias_groups.append(bg)\n",
    "\n",
    "def load_existing_results(run_name):\n",
    "    filename = f\"{run_name}_results.csv\"\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        bias_phrases = dict(zip(df['phrase'], df['last_bias']))\n",
    "        return df, bias_phrases\n",
    "    else:\n",
    "        return pd.DataFrame(columns=[\"phrase\", \"count\", \"last_bias\"]), {}\n",
    "\n",
    "def update_run_info(run_name, settings, terms_generated, terms_added, completed):\n",
    "    filename = f\"{run_name}_run_info.csv\"\n",
    "    run_info = pd.DataFrame({\n",
    "        'timestamp': [datetime.now()],\n",
    "        'terms_generated': [terms_generated],\n",
    "        'terms_added': [terms_added],\n",
    "        'completed': [completed],\n",
    "        **settings\n",
    "    })\n",
    "    if os.path.exists(filename):\n",
    "        existing_info = pd.read_csv(filename)\n",
    "        updated_info = pd.concat([existing_info, run_info], ignore_index=True)\n",
    "    else:\n",
    "        updated_info = run_info\n",
    "    updated_info.to_csv(filename, index=False)\n",
    "\n",
    "async def main():\n",
    "    # Load existing results if available\n",
    "    df, bias_phrases = load_existing_results(run_name)\n",
    "\n",
    "    # Initialize bias groups\n",
    "    bias_groups = []\n",
    "    for phrase, strength in bias_phrases.items():\n",
    "        bg = BiasGroup(strength)\n",
    "        bg.add(phrase)\n",
    "        bias_groups.append(bg)\n",
    "\n",
    "    # Counter for total generations and unsuccessful attempts\n",
    "    total_generations = 0\n",
    "    unsuccessful_attempts = 0\n",
    "    terms_added = 0\n",
    "\n",
    "    # Initialize settings_data outside the loop\n",
    "    settings_data = {\n",
    "        \"auth_method\": auth_method,\n",
    "        \"candidates_goal\": candidates_goal,\n",
    "        \"bias_strength_inc\": bias_strength_inc,\n",
    "        \"model\": str(model),\n",
    "        \"preset_name\": preset.name,\n",
    "        \"preset_settings\": str(preset._settings),\n",
    "        \"bias_phrases\": str(bias_phrases)\n",
    "    }\n",
    "\n",
    "    # Loop until you have candidate_goal unique phrases\n",
    "    while len(df) < candidates_goal:\n",
    "        total_generations += 1\n",
    "\n",
    "        # Clear the previous output\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        print(f\"Gen {total_generations}: Trying to gen phrase {len(df)+1}/{candidates_goal}...\")\n",
    "\n",
    "        try:\n",
    "            phrase = await asyncio.wait_for(\n",
    "                gen_attg_candidate(\n",
    "                    model=model,\n",
    "                    preset=preset,\n",
    "                    prompt=prompt,\n",
    "                    auth_method=auth_method,\n",
    "                    auth=auth,\n",
    "                    bias_groups=bias_groups,\n",
    "                ),\n",
    "                timeout=generation_timeout,\n",
    "            )\n",
    "\n",
    "            # Check if the phrase is already in the DataFrame\n",
    "            if phrase in df[\"phrase\"].values:\n",
    "                df.loc[df[\"phrase\"] == phrase, \"count\"] += 1\n",
    "                df.loc[df[\"phrase\"] == phrase, \"last_bias\"] = bias_phrases.get(phrase, 0)\n",
    "                print(f\"Phrase '{phrase}' already exists. Incrementing count and changing bias by {bias_strength_inc}.\")\n",
    "\n",
    "                # Update the bias groups since the phrase was generated again\n",
    "                update_bias_groups(phrase, bias_phrases, bias_strength_inc, bias_groups)\n",
    "            else:\n",
    "                df.loc[len(df)] = [phrase, 1, bias_phrases.get(phrase, 0)]\n",
    "                print(f\"Added new phrase: '{phrase}'\")\n",
    "                terms_added += 1\n",
    "\n",
    "            # Reset the unsuccessful_attempts counter if generation was successful\n",
    "            unsuccessful_attempts = 0\n",
    "\n",
    "            # Store results and settings\n",
    "            filename_results = f\"{run_name}_results.csv\"\n",
    "            df.to_csv(filename_results, index=False)\n",
    "\n",
    "            # Update settings_data with the latest bias_phrases\n",
    "            settings_data[\"bias_phrases\"] = str(bias_phrases)\n",
    "\n",
    "            print(f\"Saved progress to {filename_results}.\")\n",
    "\n",
    "        except asyncio.TimeoutError:\n",
    "            print(\"Generation took too long. Retrying...\")\n",
    "            unsuccessful_attempts += 1\n",
    "            if unsuccessful_attempts >= max_failed_gens:\n",
    "                print(f\"{max_failed_gens} unsuccessful generation attempts. Aborting candidate search.\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            if \"Anonymous quota reached\" in str(e):\n",
    "                print(f\"Error: {e}\")\n",
    "                print(\"Anonymous rate limit reached. This indicates you are not properly authenticated. Check your authentication method. Aborting candidate search.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Error: {e}\")\n",
    "                print(\"Aborting candidate search\")\n",
    "                break\n",
    "\n",
    "        # Wait for delay_time seconds before the next generation attempt\n",
    "        time.sleep(delay_time)\n",
    "\n",
    "    # Update run info\n",
    "    success = len(df) >= candidates_goal\n",
    "    update_run_info(run_name, settings_data, total_generations, terms_added, success)\n",
    "\n",
    "    print(\"\\nCandidate search complete!\")\n",
    "    print(\"Top 10 terms:\")\n",
    "    print(df.sort_values(by=\"count\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 15: Trying to gen phrase 20/20...\n",
      "Added new phrase: 'Artificial Intelligence'\n",
      "Saved progress to genre_clio_results.csv.\n",
      "\n",
      "Candidate search complete!\n",
      "                     phrase  count  last_bias\n",
      "0                    LitRPG      5       -0.3\n",
      "1                   Fantasy      2        0.0\n",
      "2                    Horror      1        0.0\n",
      "3              epic fantasy      1        0.0\n",
      "4           Crime & Mystery      1        0.0\n",
      "5    Comedy science fiction      1        0.0\n",
      "6       Interactive fiction      1        0.0\n",
      "7         alternate history      1        0.0\n",
      "8          Post-apocalyptic      1        0.0\n",
      "9        Historical fiction      1        0.0\n",
      "10                Adventure      1        0.0\n",
      "11                   Action      1        0.0\n",
      "12             Epic fantasy      1        0.0\n",
      "13                  Romance      1        0.0\n",
      "14                   comedy      1        0.0\n",
      "15          Science fiction      1        0.0\n",
      "16         Military fiction      1        0.0\n",
      "17       Age Recommendation      1        0.0\n",
      "18             Dungeon Core      1        0.0\n",
      "19  Artificial Intelligence      1        0.0\n"
     ]
    }
   ],
   "source": [
    "# Run the main function\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

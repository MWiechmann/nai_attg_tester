{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from novelai_api.NovelAI_API import NovelAIAPI\n",
    "from novelai_api.Preset import Model, Preset\n",
    "from novelai_api.GlobalSettings import GlobalSettings\n",
    "from novelai_api.Tokenizer import Tokenizer\n",
    "from novelai_api.utils import b64_to_tokens\n",
    "from novelai_api.BiasGroup import BiasGroup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "# Set method for authentication\n",
    "# Posible options are:\n",
    "# \"enter_key\" (enter your access key)\n",
    "# \"enter_login\" (enter your username & pw)\n",
    "# \"enter_token\" (enter your access token)\n",
    "# \"env_key\" (read access key from environment variable NAI_KEY)\n",
    "# \"env_login\" (read user from environment variable NAI_USERNAME and password from NAI_PASSWORD)\n",
    "# \"env_token\"\n",
    "auth_method = \"env_token\"\n",
    "delay_time = 2\n",
    "candidates_goal = 5\n",
    "bias_strength = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = False\n",
    "env = os.environ\n",
    "\n",
    "# Init variable for login method\n",
    "if auth_method == \"enter_key\":\n",
    "    auth = input(\"Enter your NovelAI access key: \")\n",
    "if auth_method == \"enter_token\":\n",
    "    auth = input(\"Enter your NovelAI access token: \")\n",
    "elif auth_method == \"enter_login\":\n",
    "    auth = {}\n",
    "    auth[\"user\"] = input(\"Enter your NovelAI username: \")\n",
    "    auth[\"pw\"] = input(\"Enter your NovelAI password: \")\n",
    "elif auth_method == \"env_key\":\n",
    "    auth = env[\"NAI_KEY\"]\n",
    "elif auth_method == \"env_token\":\n",
    "    auth = env[\"NAI_TOKEN\"]\n",
    "elif auth_method == \"env_login\":\n",
    "    auth = {}\n",
    "    auth[\"user\"] = env[\"NAI_USERNAME\"]\n",
    "    auth[\"pw\"] = env[\"NAI_PASSWORD\"]\n",
    "else:\n",
    "    raise RuntimeError(\"Invalid value for 'auth_method'. Must be one of 'enter_key', 'enter_token', 'enter_login', env_key', 'env_token' or 'env_login\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def nai_login (api, auth_method, auth):\n",
    "\n",
    "    if auth_method == \"enter_key\" or auth_method == \"env_key\":\n",
    "        await api.high_level.login_from_key(auth)\n",
    "    elif auth_method == \"enter_token\" or auth_method == \"env_token\":\n",
    "        await api.high_level.login_with_token(auth)\n",
    "    elif auth_method == \"enter_login\" or auth_method == \"env_login\":\n",
    "        await api.high_level.login(auth[\"user\"], auth[\"pw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gen_attg_candidate(model=Model.Clio, prompt=\"[ Genre:\", stop_sequences=[\",\", \";\", \" ]\"], cut_stop_seq = True, auth_method=\"env_token\", auth = None):\n",
    "    # Initialize the NovelAI API\n",
    "    api = NovelAIAPI()\n",
    "    \n",
    "    try:\n",
    "        # Ensure you're logged in\n",
    "        await nai_login(api, auth_method, auth)\n",
    "\n",
    "        # Use the official \"Edgewise\" preset\n",
    "        preset = Preset.from_official(model, \"Edgewise\")\n",
    "        \n",
    "        # Tokenize the stop sequences and set them for the preset\n",
    "        stop_sequences_tokenized = [Tokenizer.encode(model, seq) for seq in stop_sequences]\n",
    "        preset[\"stop_sequences\"] = stop_sequences_tokenized\n",
    "        \n",
    "        # Create default global settings\n",
    "        global_settings = GlobalSettings()\n",
    "\n",
    "        gen = await api.high_level.generate(prompt, model, preset, global_settings)\n",
    "        \n",
    "        # After generating the text, remove the stop sequence\n",
    "        generated_text = Tokenizer.decode(model, b64_to_tokens(gen[\"output\"]))\n",
    "        if cut_stop_seq:\n",
    "            for seq in stop_sequences:\n",
    "                generated_text = re.sub(re.escape(seq) + \"$\", \"\", generated_text).strip()\n",
    "    \n",
    "        return generated_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error generating text: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 9: Trying to gen phrase 5/5...\n",
      "Added new phrase: 'science fiction'\n",
      "\n",
      "Candidate search complete!\n",
      "            phrase count\n",
      "0           LitRPG     4\n",
      "1           Action     1\n",
      "2     Epic fantasy     1\n",
      "3          Fantasy     2\n",
      "4  science fiction     1\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame(columns=[\"phrase\", \"count\"])\n",
    "\n",
    "# Counter for total generations\n",
    "total_generations = 0\n",
    "\n",
    "# Loop until you have candidate_goal unique phrases\n",
    "while len(df) < candidates_goal:\n",
    "    total_generations += 1\n",
    "\n",
    "    ## Clear the previous output\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print(f\"Gen {total_generations}: Trying to gen phrase {len(df)+1}/{candidates_goal}...\")\n",
    "\n",
    "    try:\n",
    "        phrase = await gen_attg_candidate(model=Model.Clio, prompt=\"[ Genre:\", auth_method=auth_method, auth=auth)\n",
    "\n",
    "        # Check if the phrase is already in the DataFrame\n",
    "        if phrase in df[\"phrase\"].values:\n",
    "            df.loc[df[\"phrase\"] == phrase, \"count\"] += 1\n",
    "            print(f\"Phrase '{phrase}' already exists. Incrementing count.\")\n",
    "        else:\n",
    "            new_row = pd.DataFrame({\"phrase\": [phrase], \"count\": [1]})\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "            print(f\"Added new phrase: '{phrase}'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"Anonymous quota reached\" in str(e):\n",
    "            print(f\"Error: {e}\")\n",
    "            print(\"Anonymous rate limit reached. This indicates you are not properly authenticated. Check your authentication method. Aborting candidate search.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Error: {e}\")\n",
    "            print(\"Aborting candidate search\")\n",
    "            break\n",
    "\n",
    "    # Wait for delay_time seconds before the next generation attempt\n",
    "    time.sleep(delay_time)\n",
    "\n",
    "print(\"\\nCandidate search complete!\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api-usage-NSkpzFBI-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import configparser\n",
    "import ast\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from novelai_api.NovelAI_API import NovelAIAPI\n",
    "from novelai_api.Preset import Model, Preset\n",
    "from novelai_api.GlobalSettings import GlobalSettings\n",
    "from novelai_api.Tokenizer import Tokenizer\n",
    "from novelai_api.utils import b64_to_tokens\n",
    "from novelai_api.BiasGroup import BiasGroup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings new method\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config_template.ini')\n",
    "\n",
    "# Access the General Settings\n",
    "run_name = config['GENERAL']['run_name']\n",
    "auth_method = config['GENERAL']['auth_method']\n",
    "\n",
    "# Access the Generation Settings\n",
    "delay_time = int(config['GENERATION SETTINGS']['delay_time'])\n",
    "generation_timeout = int(config['GENERATION SETTINGS']['generation_timeout'])\n",
    "max_failed_gens = int(config['GENERATION SETTINGS']['max_failed_gens'])\n",
    "candidates_goal = int(config['GENERATION SETTINGS']['candidates_goal'])\n",
    "bias_strength_inc = float(config['GENERATION SETTINGS']['bias_strength_inc'])\n",
    "bias_phrases = ast.literal_eval(config['GENERATION SETTINGS']['bias_phrases'])\n",
    "model_class, model_attr = config['GENERATION SETTINGS']['model'].split('.')\n",
    "model = getattr(globals()[model_class], model_attr)\n",
    "prompt = config['GENERATION SETTINGS']['prompt']\n",
    "stop_sequences = ast.literal_eval(config['GENERATION SETTINGS']['stop_sequences'])\n",
    "\n",
    "# Access the Preset Configuration\n",
    "preset_method = config['PRESET']['preset_method']\n",
    "preset_name = config['PRESET']['preset_name']\n",
    "preset_stop_sequences = ast.literal_eval(config['PRESET']['preset_stop_sequences'])\n",
    "preset_temperature = float(config['PRESET']['preset_temperature'])\n",
    "preset_max_length = int(config['PRESET']['preset_max_length'])\n",
    "preset_min_length = int(config['PRESET']['preset_min_length'])\n",
    "preset_top_k = int(config['PRESET']['preset_top_k'])\n",
    "preset_top_a = float(config['PRESET']['preset_top_a'])\n",
    "preset_top_p = float(config['PRESET']['preset_top_p'])\n",
    "preset_typical_p = float(config['PRESET']['preset_typical_p'])\n",
    "preset_tail_free_sampling = float(config['PRESET']['preset_tail_free_sampling'])\n",
    "preset_repetition_penalty = float(config['PRESET']['preset_repetition_penalty'])\n",
    "preset_repetition_penalty_range = int(config['PRESET']['preset_repetition_penalty_range'])\n",
    "preset_repetition_penalty_slope = float(config['PRESET']['preset_repetition_penalty_slope'])\n",
    "preset_repetition_penalty_frequency = float(config['PRESET']['preset_repetition_penalty_frequency'])\n",
    "preset_repetition_penalty_presence = float(config['PRESET']['preset_repetition_penalty_presence'])\n",
    "preset_repetition_penalty_whitelist = ast.literal_eval(config['PRESET']['preset_repetition_penalty_whitelist'])\n",
    "preset_repetition_penalty_default_whitelist = config['PRESET']['preset_repetition_penalty_default_whitelist'] == 'True'\n",
    "preset_length_penalty = float(config['PRESET']['preset_length_penalty'])\n",
    "preset_diversity_penalty = float(config['PRESET']['preset_diversity_penalty'])\n",
    "preset_order = ast.literal_eval(config['PRESET']['preset_order'])\n",
    "preset_phrase_rep_pen = config['PRESET']['preset_phrase_rep_pen']\n",
    "\n",
    "# Assuming Preset is a class you have defined or imported\n",
    "preset = Preset(name=preset_name, model=model, settings={\n",
    "    'temperature': preset_temperature,\n",
    "    'max_length': preset_max_length,\n",
    "    'min_length': preset_min_length,\n",
    "    'top_k': preset_top_k,\n",
    "    'top_a': preset_top_a,\n",
    "    'top_p': preset_top_p,\n",
    "    'typical_p': preset_typical_p,\n",
    "    'tail_free_sampling': preset_tail_free_sampling,\n",
    "    'repetition_penalty': preset_repetition_penalty,\n",
    "    'repetition_penalty_range': preset_repetition_penalty_range,\n",
    "    'repetition_penalty_slope': preset_repetition_penalty_slope,\n",
    "    'repetition_penalty_frequency': preset_repetition_penalty_frequency,\n",
    "    'repetition_penalty_presence': preset_repetition_penalty_presence,\n",
    "    'repetition_penalty_whitelist': preset_repetition_penalty_whitelist,\n",
    "    'repetition_penalty_default_whitelist': preset_repetition_penalty_default_whitelist,\n",
    "    'length_penalty': preset_length_penalty,\n",
    "    'diversity_penalty': preset_diversity_penalty,\n",
    "    'order': preset_order,\n",
    "    'phrase_rep_pen': preset_phrase_rep_pen,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = False\n",
    "env = os.environ\n",
    "\n",
    "# Init variable for login method\n",
    "if auth_method == \"enter_key\":\n",
    "    auth = input(\"Enter your NovelAI access key: \")\n",
    "if auth_method == \"enter_token\":\n",
    "    auth = input(\"Enter your NovelAI access token: \")\n",
    "elif auth_method == \"enter_login\":\n",
    "    auth = {}\n",
    "    auth[\"user\"] = input(\"Enter your NovelAI username: \")\n",
    "    auth[\"pw\"] = input(\"Enter your NovelAI password: \")\n",
    "elif auth_method == \"env_key\":\n",
    "    auth = env[\"NAI_KEY\"]\n",
    "elif auth_method == \"env_token\":\n",
    "    auth = env[\"NAI_TOKEN\"]\n",
    "elif auth_method == \"env_login\":\n",
    "    auth = {}\n",
    "    auth[\"user\"] = env[\"NAI_USERNAME\"]\n",
    "    auth[\"pw\"] = env[\"NAI_PASSWORD\"]\n",
    "else:\n",
    "    raise RuntimeError(\n",
    "        \"Invalid value for 'auth_method'. Must be one of 'enter_key', 'enter_token', 'enter_login', env_key', 'env_token' or 'env_login\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def nai_login(api, auth_method, auth):\n",
    "    if auth_method == \"enter_key\" or auth_method == \"env_key\":\n",
    "        await api.high_level.login_from_key(auth)\n",
    "    elif auth_method == \"enter_token\" or auth_method == \"env_token\":\n",
    "        await api.high_level.login_with_token(auth)\n",
    "    elif auth_method == \"enter_login\" or auth_method == \"env_login\":\n",
    "        await api.high_level.login(auth[\"user\"], auth[\"pw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gen_attg_candidate(\n",
    "    model=Model.Clio,\n",
    "    preset = \"Edgewise\",\n",
    "    prompt=\"[ Genre:\",\n",
    "    stop_sequences=[\",\", \";\", \" ]\",\"\\n\"],\n",
    "    cut_stop_seq=True,\n",
    "    auth_method=\"env_token\",\n",
    "    auth=None,\n",
    "    bias_groups=None,\n",
    "):\n",
    "    # Initialize the NovelAI API\n",
    "    api = NovelAIAPI()\n",
    "\n",
    "    try:\n",
    "        # Ensure you're logged in\n",
    "        await nai_login(api, auth_method, auth)\n",
    "\n",
    "        # If preset is a string, get the official preset with that name for the specified model\n",
    "        if isinstance(preset, str):\n",
    "            preset = Preset.from_official(model, preset)\n",
    "\n",
    "        # Tokenize the stop sequences and set them for the preset\n",
    "        stop_sequences_tokenized = [\n",
    "            Tokenizer.encode(model, seq) for seq in stop_sequences\n",
    "        ]\n",
    "        preset[\"stop_sequences\"] = stop_sequences_tokenized\n",
    "\n",
    "        # Create default global settings\n",
    "        global_settings = GlobalSettings()\n",
    "\n",
    "        gen = await api.high_level.generate(\n",
    "            prompt, model, preset, global_settings, None, bias_groups, None\n",
    "        )\n",
    "\n",
    "        # After generating the text, remove the stop sequence\n",
    "        generated_text = Tokenizer.decode(model, b64_to_tokens(gen[\"output\"]))\n",
    "        if cut_stop_seq:\n",
    "            for seq in stop_sequences:\n",
    "                generated_text = re.sub(\n",
    "                    re.escape(seq) + \"$\", \"\", generated_text\n",
    "                ).strip()\n",
    "\n",
    "        return generated_text\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error generating text: {e}\")\n",
    "\n",
    "\n",
    "def update_bias_groups(phrase, bias_phrase_dict, bias_strength_inc, bias_groups):\n",
    "    # Update the bias strength for the phrase or add it if it's not in the dict\n",
    "    if phrase in bias_phrase_dict:\n",
    "        bias_phrase_dict[phrase] += bias_strength_inc\n",
    "    else:\n",
    "        bias_phrase_dict[phrase] = bias_strength_inc\n",
    "\n",
    "    # Clear the existing bias groups\n",
    "    bias_groups.clear()\n",
    "\n",
    "    # Regenerate the bias groups based on the updated bias_phrase_dict\n",
    "    for phrase, strength in bias_phrase_dict.items():\n",
    "        bg = BiasGroup(strength)\n",
    "        bg.add(phrase)\n",
    "        bias_groups.append(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 12: Trying to gen phrase 10/10...\n",
      "Added new phrase: 'Adventure'\n",
      "Saved progress to genre_clio_results.csv and genre_clio_settings.json.\n",
      "\n",
      "Candidate search complete!\n",
      "                   phrase  count  last_bias\n",
      "0                  LitRPG      3       -0.1\n",
      "1                 Fantasy      1        0.0\n",
      "2            Epic fantasy      1        0.0\n",
      "3                 fantasy      1        0.0\n",
      "4                  Action      1        0.0\n",
      "5  Adventure & Historical      1        0.0\n",
      "6                    BDSM      1        0.0\n",
      "7              Nonfiction      1        0.0\n",
      "8        Military fiction      1        0.0\n",
      "9               Adventure      1        0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame(columns=[\"phrase\", \"count\", \"last_bias\"])\n",
    "\n",
    "# Counter for total generations\n",
    "total_generations = 0\n",
    "\n",
    "# set phrase biases\n",
    "bias_groups = []\n",
    "for phrase, strength in bias_phrases.items():\n",
    "    bg = BiasGroup(strength)\n",
    "    bg.add(phrase)\n",
    "    bias_groups.append(bg)\n",
    "\n",
    "# Counter for unsuccessful generation attempts\n",
    "unsuccessful_attempts = 0\n",
    "\n",
    "# Loop until you have candidate_goal unique phrases\n",
    "while len(df) < candidates_goal:\n",
    "    total_generations += 1\n",
    "\n",
    "    ## Clear the previous output\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    print(\n",
    "        f\"Gen {total_generations}: Trying to gen phrase {len(df)+1}/{candidates_goal}...\"\n",
    "    )\n",
    "    # print(f\"Current bias groups {bias_phrases}\")\n",
    "\n",
    "    try:\n",
    "        phrase = await asyncio.wait_for(\n",
    "            gen_attg_candidate(\n",
    "                model=Model.Clio,\n",
    "                preset=preset,\n",
    "                prompt=\"[ Genre:\",\n",
    "                auth_method=auth_method,\n",
    "                auth=auth,\n",
    "                bias_groups=bias_groups,\n",
    "            ),\n",
    "            timeout=generation_timeout,\n",
    "        )\n",
    "\n",
    "        # Check if the phrase is already in the DataFrame\n",
    "        if phrase in df[\"phrase\"].values:\n",
    "            df.loc[df[\"phrase\"] == phrase, \"count\"] += 1\n",
    "            df.loc[df[\"phrase\"] == phrase, \"last_bias\"] = bias_phrases.get(\n",
    "                phrase, 0\n",
    "            )\n",
    "            print(\n",
    "                f\"Phrase '{phrase}' already exists. Incrementing count and changing bias by {bias_strength_inc}.\"\n",
    "            )\n",
    "\n",
    "            # Update the bias groups since the phrase was generated again\n",
    "            update_bias_groups(phrase, bias_phrases, bias_strength_inc, bias_groups)\n",
    "        else:\n",
    "            df.loc[len(df)] = [\n",
    "                phrase,\n",
    "                1,\n",
    "                bias_phrases.get(phrase, 0),\n",
    "            ]\n",
    "            print(f\"Added new phrase: '{phrase}'\")\n",
    "\n",
    "        # Reset the unsuccessful_attempts counter if generation was successful\n",
    "        unsuccessful_attempts = 0\n",
    "\n",
    "        # store results, settings and current bias_phrases\n",
    "        filename_results = f\"{run_name}_results.csv\"\n",
    "        df.to_csv(filename_results, index=False)\n",
    "\n",
    "        settings_data = {\n",
    "            \"auth_method\": auth_method,\n",
    "            \"candidates_goal\": candidates_goal,\n",
    "            \"bias_strength_inc\": bias_strength_inc,\n",
    "            \"model\": model,\n",
    "            \"preset_name\": preset.name,\n",
    "            \"preset_settings\": preset._settings,\n",
    "            \"bias_phrases\": bias_phrases\n",
    "            }\n",
    "        \n",
    "        filename_settings = f\"{run_name}_settings.json\"\n",
    "        with open(filename_settings, 'w') as f:\n",
    "            json.dump(settings_data, f, indent=4)\n",
    "\n",
    "        print(f\"Saved progress to {filename_results} and {filename_settings}.\")\n",
    "\n",
    "    except asyncio.TimeoutError:\n",
    "        print(\"Generation took too long. Retrying...\")\n",
    "        unsuccessful_attempts += 1\n",
    "        if unsuccessful_attempts >= 3:\n",
    "            print(\"3 unsuccessful generation attempts. Aborting candidate search.\")\n",
    "            break\n",
    "    except Exception as e:\n",
    "        if \"Anonymous quota reached\" in str(e):\n",
    "            print(f\"Error: {e}\")\n",
    "            print(\n",
    "                \"Anonymous rate limit reached. This indicates you are not properly authenticated. Check your authentication method. Aborting candidate search.\"\n",
    "            )\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Error: {e}\")\n",
    "            # import traceback\n",
    "            # traceback.print_exc()\n",
    "            print(\"Aborting candidate search\")\n",
    "            break\n",
    "\n",
    "    # Wait for delay_time seconds before the next generation attempt\n",
    "    time.sleep(delay_time)\n",
    "\n",
    "print(\"\\nCandidate search complete!\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api-usage-NSkpzFBI-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
